{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NN(m1, m2, w1, w2, b):\n",
    "    z = m1 * w1 + m2 * w2 + b\n",
    "    return sigmoid(z)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + numpy.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w1 = numpy.random.randn() #回傳具有常態分佈的數據\n",
    "w2 = numpy.random.randn() #回傳具有常態分佈的數據\n",
    "b = numpy.random.randn() #回傳具有常態分佈的數據"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9906518535322886"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN(3,1.5,w1,w2,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0ee43953d064>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mm2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrand_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprediction_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'藍色'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'紅色'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#取四捨五入後的數值\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mphrase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrases\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprediction_text\u001b[0m \u001b[0;31m#隨機取phrases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'NN' is not defined"
     ]
    }
   ],
   "source": [
    "phrases = ['看起來像', '我猜是', '我想是', '可能是', '看起來像是', '猜測....']\n",
    "data = [[3,1.5,1],[2,1,0],[4,1.5,1],[3,1,0],[3.5,5,1],[2,0.5,0],[5.5,1,1],[1,1,0]]\n",
    "rand_data = data[numpy.random.randint(len(data))] #隨機產生len(data)-1的index\n",
    "m1 = rand_data[0]\n",
    "m2 = rand_data[1]\n",
    "\n",
    "prediction = NN(m1,m2,w1,w2,b)\n",
    "prediction_text = ['藍色','紅色'][int(numpy.round(prediction))] #取四捨五入後的數值\n",
    "phrase = numpy.random.choice(phrases) + \"\" + prediction_text #隨機取phrases\n",
    "o =('這個' + phrase + \"\\n真的是\"+ ['藍色','紅色'][rand_data[2]])\n",
    "print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "import os\n",
    "tts = gTTS(o, lang='zh-tw')\n",
    "tts.save(\"hello.mp3\")\n",
    "\n",
    "from pygame import mixer\n",
    "mixer.init()\n",
    "mixer.music.load('hello.mp3')\n",
    "mixer.music.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual :\n",
      " [[1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]] \n",
      "\n",
      "predicted :\n",
      " [[0.99082698]\n",
      " [0.97970307]\n",
      " [0.01622142]\n",
      " [0.01618626]\n",
      " [0.99926164]\n",
      " [0.00816556]\n",
      " [0.98386654]\n",
      " [0.01271598]]\n"
     ]
    }
   ],
   "source": [
    "## Advanced Neural network in numpy 可自行設定層數\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#Input array\n",
    "X=np.array([[3,1.5],[2,1],[4,1.5],[3,1],[3.5,5],[2,0.5],[5.5,1],[1,1]])\n",
    "\n",
    "#Output\n",
    "y=np.array([[1],[1],[0],[0],[1],[0],[1],[0]])\n",
    "\n",
    "#Sigmoid Function\n",
    "def sigmoid (x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "#Sigmoid Function for backpropagation\n",
    "def derivatives_sigmoid (x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "#Variable initialization\n",
    "epoch=50000 #Setting training iterations\n",
    "lr=0.1 #Setting learning rate\n",
    "inputlayer_neurons = X.shape[1] #number of features in data set\n",
    "hiddenlayer_neurons = 20 #number of hidden layers neurons\n",
    "output_neurons = 1 #number of neurons at output layer\n",
    "\n",
    "#weight and bias initialization\n",
    "wh=np.random.uniform(size=(inputlayer_neurons,hiddenlayer_neurons)) #均勻分布\n",
    "bh=np.random.uniform(size=(1,hiddenlayer_neurons))\n",
    "wout=np.random.uniform(size=(hiddenlayer_neurons,output_neurons))\n",
    "bout=np.random.uniform(size=(1,output_neurons))\n",
    "\n",
    "for i in range(epoch):\n",
    "  #Forward Propogation\n",
    "  hidden_layer_input1=np.dot(X,wh)#做內積\n",
    "  hidden_layer_input=hidden_layer_input1 + bh\n",
    "  hiddenlayer_activations = sigmoid(hidden_layer_input)\n",
    "  output_layer_input1=np.dot(hiddenlayer_activations,wout)\n",
    "  output_layer_input= output_layer_input1+ bout\n",
    "  output = sigmoid(output_layer_input)\n",
    "\n",
    "  #Backpropagation\n",
    "  E = y-output #Loss差異\n",
    "  back_output_layer = derivatives_sigmoid(output)\n",
    "  back_hidden_layer = derivatives_sigmoid(hiddenlayer_activations)\n",
    "  d_output = E * back_output_layer\n",
    "  Error_at_hidden_layer = d_output.dot(wout.T) #轉置後才能乘back_hidden_layer\n",
    "  d_hiddenlayer = Error_at_hidden_layer * back_hidden_layer\n",
    "  wout += hiddenlayer_activations.T.dot(d_output) *lr #乘以學習率之後，再每次迴圈判斷Error\n",
    "  bout += np.sum(d_output, axis=0,keepdims=True) *lr #乘以學習率之後，再每次迴圈判斷Error\n",
    "  wh += X.T.dot(d_hiddenlayer) *lr \n",
    "  bh += np.sum(d_hiddenlayer, axis=0,keepdims=True) *lr #keepdims保持矩陣二維特性\n",
    "    \n",
    "  #numpy_E = np.array(E) \n",
    "  #Loss_E = np.sum((numpy_E)**2)/len(numpy_E)\n",
    "  #print(\"E\",Loss_E)\n",
    "  \n",
    "    \n",
    "print('actual :\\n', y, '\\n')\n",
    "print('predicted :\\n', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual :\n",
      " [[1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]] \n",
      "\n",
      "predicted :\n",
      " [[0.99082698]\n",
      " [0.97970307]\n",
      " [0.01622142]\n",
      " [0.01618626]\n",
      " [0.99926164]\n",
      " [0.00816556]\n",
      " [0.98386654]\n",
      " [0.01271598]]\n"
     ]
    }
   ],
   "source": [
    "print('actual :\\n', y, '\\n')\n",
    "print('predicted :\\n', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "這個我想是紅色\n",
      "真的是紅色\n"
     ]
    }
   ],
   "source": [
    "#prediction = NN(m1,m2,w1,w2,b)\n",
    "phrases = ['看起來像', '我猜是', '我想是', '可能是', '看起來像是', '猜測....']\n",
    "prediction_text = ['藍色','紅色'][int(numpy.round(output[0]))] #取四捨五入後的數值\n",
    "phrase = numpy.random.choice(phrases) + \"\" + prediction_text #隨機取phrases\n",
    "o = '這個' + phrase + \"\\n真的是\"+ ['藍色','紅色'][int(y[0])]\n",
    "print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual :\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]] \n",
      "\n",
      "predicted :\n",
      " [[0.00518985]\n",
      " [0.99643878]\n",
      " [0.99646974]\n",
      " [0.00518985]\n",
      " [0.99643878]\n",
      " [0.99646974]]\n"
     ]
    }
   ],
   "source": [
    "## Advanced Neural network in numpy 可自行設定層數\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#Input array\n",
    "X=np.array([[0,0,1],[0,1,0],[1,0,0],[0,0,1],[0,1,0],[1,0,0]])\n",
    "\n",
    "#Output\n",
    "y=np.array([[0],[1],[1],[0],[1],[1]])\n",
    "\n",
    "#Sigmoid Function\n",
    "def sigmoid (x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "#Sigmoid Function for backpropagation\n",
    "def derivatives_sigmoid (x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "#Variable initialization\n",
    "epoch=50000 #Setting training iterations\n",
    "lr=0.1 #Setting learning rate\n",
    "inputlayer_neurons = X.shape[1] #number of features in data set\n",
    "hiddenlayer_neurons = 20 #number of hidden layers neurons\n",
    "output_neurons = 1 #number of neurons at output layer\n",
    "\n",
    "#weight and bias initialization\n",
    "wh=np.random.uniform(size=(inputlayer_neurons,hiddenlayer_neurons)) #均勻分布\n",
    "bh=np.random.uniform(size=(1,hiddenlayer_neurons))\n",
    "wout=np.random.uniform(size=(hiddenlayer_neurons,output_neurons))\n",
    "bout=np.random.uniform(size=(1,output_neurons))\n",
    "\n",
    "for i in range(epoch):\n",
    "  #Forward Propogation\n",
    "  hidden_layer_input1=np.dot(X,wh)#做內積\n",
    "  hidden_layer_input=hidden_layer_input1 + bh\n",
    "  hiddenlayer_activations = sigmoid(hidden_layer_input)\n",
    "  output_layer_input1=np.dot(hiddenlayer_activations,wout)\n",
    "  output_layer_input= output_layer_input1+ bout\n",
    "  output = sigmoid(output_layer_input)\n",
    "\n",
    "  #Backpropagation\n",
    "  E = y-output #Loss差異\n",
    "  back_output_layer = derivatives_sigmoid(output)\n",
    "  back_hidden_layer = derivatives_sigmoid(hiddenlayer_activations)\n",
    "  d_output = E * back_output_layer\n",
    "  Error_at_hidden_layer = d_output.dot(wout.T) #轉置後才能乘back_hidden_layer\n",
    "  d_hiddenlayer = Error_at_hidden_layer * back_hidden_layer\n",
    "  wout += hiddenlayer_activations.T.dot(d_output) *lr #乘以學習率之後，再每次迴圈判斷Error\n",
    "  bout += np.sum(d_output, axis=0,keepdims=True) *lr #乘以學習率之後，再每次迴圈判斷Error\n",
    "  wh += X.T.dot(d_hiddenlayer) *lr \n",
    "  bh += np.sum(d_hiddenlayer, axis=0,keepdims=True) *lr #keepdims保持矩陣二維特性\n",
    "    \n",
    "  #numpy_E = np.array(E) \n",
    "  #Loss_E = np.sum((numpy_E)**2)/len(numpy_E)\n",
    "  #print(\"E\",Loss_E)\n",
    "  \n",
    "    \n",
    "print('actual :\\n', y, '\\n')\n",
    "print('predicted :\\n', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
